#!/usr/bin/env python3
"""
Script de Teste Completo do Sistema RAG Notecraft
Executa todos os componentes e demonstra funcionalidades
"""

import os
import sys
import time
import json
from datetime import datetime

def print_banner():
    """Exibe banner do sistema"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸš€ SISTEMA RAG NOTECRAFT - TESTE COMPLETO                â•‘
â•‘                                                                              â•‘
â•‘  Sistema RAG Profissional com MÃºltiplas EstratÃ©gias e AvaliaÃ§Ã£o CientÃ­fica  â•‘
â•‘                              VersÃ£o 1.0.0                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)

def test_imports():
    """Testa importaÃ§Ã£o de todos os mÃ³dulos"""
    print("\nğŸ” TESTE 1: Verificando MÃ³dulos do Sistema")
    print("-" * 60)
    
    modules = [
        ('rag_agent', 'RAGAgent'),
        ('document_processor', 'DocumentProcessor'),
        ('chunking_engine', 'ChunkingEngine'),
        ('embedding_generator', 'EmbeddingGenerator'),
        ('evaluation_system', 'EvaluationSystem')
    ]
    
    results = {}
    
    for module_name, class_name in modules:
        try:
            module = __import__(module_name)
            cls = getattr(module, class_name)
            results[module_name] = {'status': 'âœ…', 'class': cls}
            print(f"âœ… {module_name}.{class_name} - OK")
        except ImportError as e:
            results[module_name] = {'status': 'âŒ', 'error': str(e)}
            print(f"âŒ {module_name} - ERRO: {e}")
        except AttributeError as e:
            results[module_name] = {'status': 'âš ï¸', 'error': str(e)}
            print(f"âš ï¸ {module_name} - CLASSE NÃƒO ENCONTRADA: {e}")
    
    return results

def test_document_processing():
    """Testa processamento de documentos"""
    print("\nğŸ“„ TESTE 2: Processamento de Documentos")
    print("-" * 60)
    
    try:
        from document_processor import DocumentProcessor
        
        processor = DocumentProcessor()
        
        # Criar documento de teste
        test_content = """
POLÃTICA DE FÃ‰RIAS - EMPRESA TESTE

1. DIREITO A FÃ‰RIAS
Todo funcionÃ¡rio tem direito a 30 dias de fÃ©rias apÃ³s 12 meses de trabalho.

2. SOLICITAÃ‡ÃƒO
- FÃ©rias devem ser solicitadas com 30 dias de antecedÃªncia
- SolicitaÃ§Ã£o deve ser feita atravÃ©s do sistema interno
- AprovaÃ§Ã£o depende do gestor direto

3. PERÃODOS
- FÃ©rias podem ser divididas em atÃ© 3 perÃ­odos
- Pelo menos um perÃ­odo deve ter no mÃ­nimo 14 dias
        """
        
        # Criar arquivo temporÃ¡rio
        temp_file = "temp_test_doc.txt"
        with open(temp_file, 'w', encoding='utf-8') as f:
            f.write(test_content)
        
        # Testar extraÃ§Ã£o
        result = processor.extract_text(temp_file)
        
        print(f"âœ… Arquivo processado: {result['file_name']}")
        print(f"ğŸ“Š Caracteres extraÃ­dos: {len(result['content'])}")
        print(f"ğŸ”§ Formato: {result['format']}")
        
        # Limpar arquivo temporÃ¡rio
        os.remove(temp_file)
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste de processamento: {e}")
        return False

def test_chunking_strategies():
    """Testa estratÃ©gias de chunking"""
    print("\nğŸ”§ TESTE 3: EstratÃ©gias de Chunking")
    print("-" * 60)
    
    try:
        from chunking_engine import ChunkingEngine
        
        # ConfiguraÃ§Ã£o de teste
        config = {
            'recursive_500_100': {
                'type': 'recursive',
                'chunk_size': 500,
                'chunk_overlap': 100
            },
            'token_400_50': {
                'type': 'token',
                'chunk_size': 400,
                'chunk_overlap': 50
            },
            'semantic_auto': {
                'type': 'semantic',
                'max_chunk_size': 1000,
                'min_chunk_size': 200
            }
        }
        
        engine = ChunkingEngine(config)
        
        # Texto de teste
        test_text = """
        A inteligÃªncia artificial estÃ¡ revolucionando diversos setores da economia.
        
        No setor financeiro, algoritmos de machine learning estÃ£o sendo usados para detectar fraudes.
        
        Na medicina, sistemas de IA auxiliam no diagnÃ³stico precoce de doenÃ§as.
        
        No varejo, chatbots automatizados melhoram o atendimento ao cliente.
        
        A automaÃ§Ã£o de processos estÃ¡ aumentando a eficiÃªncia operacional.
        """
        
        strategies = ['recursive_500_100', 'semantic_auto']
        
        for strategy in strategies:
            chunks = engine.create_chunks(test_text, strategy)
            print(f"âœ… {strategy}: {len(chunks)} chunks criados")
            
            if chunks:
                avg_size = sum(len(chunk['text']) for chunk in chunks) / len(chunks)
                print(f"   ğŸ“Š Tamanho mÃ©dio: {avg_size:.0f} caracteres")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste de chunking: {e}")
        return False

def test_embeddings():
    """Testa geraÃ§Ã£o de embeddings"""
    print("\nğŸ”— TESTE 4: GeraÃ§Ã£o de Embeddings")
    print("-" * 60)
    
    try:
        from embedding_generator import EmbeddingGenerator
        
        # Usar fallback para demo (nÃ£o requer API keys)
        generator = EmbeddingGenerator(provider='fallback')
        
        test_texts = [
            "Como solicitar fÃ©rias na empresa?",
            "PolÃ­tica de fÃ©rias estabelece 30 dias anuais",
            "Procedimento para aprovaÃ§Ã£o de fÃ©rias"
        ]
        
        embeddings = generator.generate_embeddings(test_texts)
        
        print(f"âœ… Embeddings gerados: {len(embeddings)}")
        if embeddings:
            print(f"ğŸ“Š DimensÃµes: {len(embeddings[0])}")
            
            # Testar similaridade
            if len(embeddings) >= 2:
                similarity = generator.calculate_similarity(embeddings[0], embeddings[1])
                print(f"ğŸ” Similaridade entre textos 0 e 1: {similarity:.3f}")
        
        # EstatÃ­sticas
        stats = generator.get_embedding_stats(embeddings)
        print(f"ğŸ“ˆ EstatÃ­sticas: {stats.get('count', 0)} embeddings, provedor: {stats.get('provider', 'N/A')}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste de embeddings: {e}")
        return False

def test_evaluation():
    """Testa sistema de avaliaÃ§Ã£o"""
    print("\nğŸ“Š TESTE 5: Sistema de AvaliaÃ§Ã£o")
    print("-" * 60)
    
    try:
        from evaluation_system import EvaluationSystem
        
        evaluator = EvaluationSystem(llm_provider='fallback')
        
        # Dados de teste
        test_question = "Como solicitar fÃ©rias?"
        test_answer = "Para solicitar fÃ©rias, vocÃª deve fazer a solicitaÃ§Ã£o com 30 dias de antecedÃªncia atravÃ©s do sistema interno, com aprovaÃ§Ã£o do gestor direto."
        test_docs = [
            {
                'text': 'FÃ©rias devem ser solicitadas com 30 dias de antecedÃªncia atravÃ©s do sistema interno',
                'source': 'politica_ferias.txt',
                'similarity_score': 0.85
            },
            {
                'text': 'AprovaÃ§Ã£o depende do gestor direto',
                'source': 'politica_ferias.txt',
                'similarity_score': 0.78
            }
        ]
        
        # Avaliar resposta
        evaluation = evaluator.evaluate_rag_response(
            test_question, test_answer, test_docs
        )
        
        print(f"âœ… AvaliaÃ§Ã£o concluÃ­da")
        print(f"ğŸ“Š Score Geral: {evaluation['overall_score']:.2f}/10")
        
        # Mostrar mÃ©tricas principais
        metrics = evaluation.get('metrics', {})
        if 'retrieval' in metrics:
            print(f"ğŸ” Retrieval: {metrics['retrieval'].get('retrieval_score', 0):.1f}/10")
        if 'relevance' in metrics:
            print(f"ğŸ¯ RelevÃ¢ncia: {metrics['relevance'].get('relevance_score', 0):.1f}/10")
        if 'completeness' in metrics:
            print(f"ğŸ“ Completude: {metrics['completeness'].get('completeness_score', 0):.1f}/10")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no teste de avaliaÃ§Ã£o: {e}")
        return False

def test_full_rag_pipeline():
    """Testa pipeline RAG completo"""
    print("\nğŸš€ TESTE 6: Pipeline RAG Completo")
    print("-" * 60)
    
    try:
        from rag_agent import RAGAgent
        
        # Inicializar agente
        agent = RAGAgent()
        
        if not agent.initialize_system():
            print("âŒ Falha na inicializaÃ§Ã£o do sistema")
            return False
        
        print("âœ… Sistema RAG inicializado com sucesso")
        
        # Criar documento de exemplo em memÃ³ria
        sample_docs = [
            {
                'text': 'Todo funcionÃ¡rio tem direito a 30 dias de fÃ©rias apÃ³s 12 meses de trabalho. FÃ©rias devem ser solicitadas com 30 dias de antecedÃªncia.',
                'source': 'politica_ferias.txt',
                'chunk_id': 'doc1_chunk1'
            },
            {
                'text': 'A solicitaÃ§Ã£o deve ser feita atravÃ©s do sistema interno com aprovaÃ§Ã£o do gestor direto. FÃ©rias podem ser divididas em atÃ© 3 perÃ­odos.',
                'source': 'politica_ferias.txt', 
                'chunk_id': 'doc1_chunk2'
            }
        ]
        
        # Adicionar documentos ao agente (simular carregamento)
        agent.documents = sample_docs
        
        # Testar query
        test_question = "Quantos dias de fÃ©rias tenho direito?"
        
        print(f"â“ Pergunta: {test_question}")
        
        result = agent.query(test_question)
        
        print(f"âœ… Resposta gerada em {result['processing_time']:.2f}s")
        print(f"ğŸ¤– Resposta: {result['answer']}")
        print(f"ğŸ“Š ConfianÃ§a: {result['confidence']:.1%}")
        print(f"ğŸ“š Fontes: {', '.join(result['sources'])}")
        
        # Verificar mÃ©tricas do agente
        metrics = agent.get_metrics()
        print(f"ğŸ“ˆ Total de consultas: {metrics['total_queries']}")
        print(f"ğŸ“ˆ Taxa de sucesso: {metrics['success_rate']:.1%}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro no pipeline completo: {e}")
        return False

def test_configuration():
    """Testa carregamento de configuraÃ§Ã£o"""
    print("\nâš™ï¸ TESTE 7: ConfiguraÃ§Ã£o do Sistema")
    print("-" * 60)
    
    try:
        import yaml
        
        # Verificar se config.yaml existe
        if os.path.exists('config.yaml'):
            with open('config.yaml', 'r') as f:
                config = yaml.safe_load(f)
            
            print("âœ… Arquivo config.yaml carregado")
            
            # Verificar seÃ§Ãµes principais
            sections = ['chunking_strategies', 'retrieval_configs', 'llm_config', 'embedding_config']
            
            for section in sections:
                if section in config:
                    count = len(config[section]) if isinstance(config[section], dict) else 1
                    print(f"âœ… {section}: {count} configuraÃ§Ãµes")
                else:
                    print(f"âš ï¸ {section}: seÃ§Ã£o nÃ£o encontrada")
            
            return True
        else:
            print("âš ï¸ Arquivo config.yaml nÃ£o encontrado")
            return False
            
    except ImportError:
        print("âš ï¸ PyYAML nÃ£o instalado - usando configuraÃ§Ãµes padrÃ£o")
        return True
    except Exception as e:
        print(f"âŒ Erro carregando configuraÃ§Ã£o: {e}")
        return False

def generate_test_report(results):
    """Gera relatÃ³rio dos testes"""
    print("\n" + "="*80)
    print("ğŸ“‹ RELATÃ“RIO FINAL DOS TESTES")
    print("="*80)
    
    total_tests = len(results)
    passed_tests = sum(1 for r in results.values() if r)
    
    print(f"\nâœ… Testes Aprovados: {passed_tests}/{total_tests}")
    print(f"ğŸ“Š Taxa de Sucesso: {(passed_tests/total_tests)*100:.1f}%")
    
    print("\nğŸ“ Detalhes por Teste:")
    test_names = [
        "ImportaÃ§Ã£o de MÃ³dulos",
        "Processamento de Documentos", 
        "EstratÃ©gias de Chunking",
        "GeraÃ§Ã£o de Embeddings",
        "Sistema de AvaliaÃ§Ã£o",
        "Pipeline RAG Completo",
        "ConfiguraÃ§Ã£o do Sistema"
    ]
    
    for i, (test_name, status) in enumerate(zip(test_names, results.values())):
        status_icon = "âœ…" if status else "âŒ"
        print(f"{status_icon} {test_name}")
    
    if passed_tests == total_tests:
        print(f"\nğŸ‰ TODOS OS TESTES PASSARAM! Sistema RAG totalmente funcional.")
        print("ğŸš€ VocÃª pode executar o sistema com: python rag_agent.py")
    else:
        print(f"\nâš ï¸ {total_tests - passed_tests} teste(s) falharam. Verifique as dependÃªncias:")
        print("   - pip install -r requirements.txt")
        print("   - Configure as variÃ¡veis de ambiente necessÃ¡rias")
    
    print("\nğŸ“š PrÃ³ximos Passos:")
    print("   1. Configure suas API keys (OpenAI, etc.)")
    print("   2. Adicione seus documentos na pasta data/raw/")
    print("   3. Execute: python rag_agent.py")
    print("   4. Acesse a interface web: abra interface-demo.html")

def main():
    """FunÃ§Ã£o principal do teste"""
    print_banner()
    
    print("ğŸ” Iniciando Testes do Sistema RAG Notecraft...")
    print(f"â° HorÃ¡rio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Executar todos os testes
    results = {}
    
    # Teste 1: ImportaÃ§Ãµes
    import_results = test_imports()
    results['imports'] = all(r.get('status') == 'âœ…' for r in import_results.values())
    
    # Teste 2: Processamento de documentos
    results['document_processing'] = test_document_processing()
    
    # Teste 3: Chunking
    results['chunking'] = test_chunking_strategies()
    
    # Teste 4: Embeddings
    results['embeddings'] = test_embeddings()
    
    # Teste 5: AvaliaÃ§Ã£o
    results['evaluation'] = test_evaluation()
    
    # Teste 6: Pipeline completo
    results['full_pipeline'] = test_full_rag_pipeline()
    
    # Teste 7: ConfiguraÃ§Ã£o
    results['configuration'] = test_configuration()
    
    # Gerar relatÃ³rio
    generate_test_report(results)
    
    return results

if __name__ == "__main__":
    try:
        results = main()
        
        # Sair com cÃ³digo apropriado
        if all(results.values()):
            sys.exit(0)  # Sucesso
        else:
            sys.exit(1)  # Falha
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Testes interrompidos pelo usuÃ¡rio")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ Erro durante execuÃ§Ã£o dos testes: {e}")
        sys.exit(1)
